# ECG-Based MI Risk Prediction Using Deep Learning & Causal Analysis

**Capstone Project - MIMIC-IV-ECG Analysis**  
**Date:** November 2, 2025  
**Status:** ðŸ”„ Phase D.3 Training (Epoch 15/160)

---

## ðŸ“‹ Project Overview

This project develops a deep learning pipeline to analyze 12-lead ECG signals from MIMIC-IV for myocardial infarction (MI) risk prediction using:
- **Î²-VAE** (Variational Autoencoder) for unsupervised ECG representation learning
- **Causal Analysis** (CATE estimation) to identify high-risk patient subgroups
- **Clinical Validation** with adjudication and interpretability checks

### Key Objectives
1. Extract meaningful latent representations from 12-lead ECG signals
2. Identify pre-incident MI signatures in asymptomatic patients
3. Estimate conditional average treatment effects (CATE) for targeted interventions
4. Validate findings through clinical adjudication and negative controls

---

## ðŸ—ï¸ Project Structure

```
Capstone/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ requirements.yml                   # Conda environment
â”œâ”€â”€ install_vae_requirements.ps1       # Installation script
â”‚
â”œâ”€â”€ src/                               # Source code
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ vae_conv1d.py             # Conv1D Î²-VAE (82.4M params)
â”‚   â”‚   â””â”€â”€ train_vae.py              # Training pipeline
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ ecg_dataset.py            # PyTorch Dataset
â”‚   â”‚   â”œâ”€â”€ phase_b_ingestion.py      # Data ingestion
â”‚   â”‚   â””â”€â”€ phase_c_cohort_labeling.py # Cohort creation
â”‚   â””â”€â”€ features/
â”‚       â””â”€â”€ phase_d_feature_extraction.py # ECG feature extraction
â”‚
â”œâ”€â”€ scripts/                           # Utility scripts
â”‚   â”œâ”€â”€ extract_latent_embeddings.py  # Phase D.4
â”‚   â”œâ”€â”€ validate_latent_interpretability.py # Phase D.5
â”‚   â”œâ”€â”€ preflight_vae_training.py     # Pre-training checks
â”‚   â””â”€â”€ analyze_adjudication.py       # Clinical validation
â”‚
â”œâ”€â”€ data/                              # Datasets
â”‚   â”œâ”€â”€ raw/                          # Original MIMIC-IV-ECG data
â”‚   â”œâ”€â”€ processed/                    # Processed parquet files
â”‚   â””â”€â”€ interim/                      # Intermediate outputs
â”‚
â”œâ”€â”€ models/checkpoints/                # VAE training checkpoints
â”œâ”€â”€ notebooks/                         # Analysis notebooks
â”œâ”€â”€ reports/                           # Reports and figures
â””â”€â”€ cuda_env/                         # Python virtual environment
```

---

## ðŸš€ Quick Start

### Prerequisites
- Windows OS with PowerShell
- NVIDIA GPU (RTX 4050, 6GB VRAM tested)
- Python 3.12+ with CUDA support
- MIMIC-IV-ECG dataset access

### Installation

```powershell
# 1. Clone/navigate to project directory
cd C:\Users\Acer\Desktop\Capstone\Capstone

# 2. Activate virtual environment
.\cuda_env\Scripts\activate

# 3. Install required packages (if not already installed)
.\install_vae_requirements.ps1

# 4. Verify installation
python scripts/preflight_vae_training.py
```

### Current Training Status

**VAE Training (Phase D.3):**
- Model: Conv1D Î²-VAE with 82.4M parameters
- Training: Epoch 15/160 (Î²-annealing cycle 1/4)
- Dataset: 44,830 ECGs (Control_Symptomatic + MI_Pre-Incident)
- Hardware: RTX 4050 GPU (~70% utilization, batch_size=256)

**Latest Metrics (Epoch 13 - Best):**
```
Val Loss:   34,857 (Recon: 34,282, KL_raw: 272)
Train Loss: 31,651 (Recon: 31,456, KL_raw: 290)
Learning Rate: 1e-4, Î²: 1.20
```

---

## ðŸ“Š Dataset Information

### MIMIC-IV-ECG Dataset
- **Total ECGs**: 47,852 unique studies
- **Patients**: ~1,000 unique subjects
- **Format**: WFDB 12-lead (500 Hz, 10 seconds)
- **Location**: `data/raw/MIMIC-IV-ECG-1.0/files/`

### Cohort Labels
| Label | Count | Purpose |
|-------|-------|---------|
| Control_Symptomatic | 41,894 | Training (normal physiology) |
| MI_Pre-Incident | 2,936 | Training (pre-MI signatures) |
| MI_Acute_Presentation | 3,022 | Hold-out (CATE analysis) |

### Processed Data
- **Features**: `data/processed/ecg_features_with_demographics.parquet` (47,852 Ã— 29)
- **Cohorts**: `cohort_master.parquet`, `cohort_strict.parquet`, `cohort_broad.parquet`
- **Database**: `data/mimic_database.duckdb` (DuckDB indexed)

---

## ðŸ”§ Phase-by-Phase Workflow

### Phase A: Project Planning âœ…
- [x] Define research question
- [x] Select datasets (MIMIC-IV-ECG, PTB-XL)
- [x] Plan analysis pipeline

### Phase B: Data Ingestion âœ…
- [x] Download MIMIC-IV-ECG (1.0)
- [x] Create DuckDB database
- [x] Index record metadata
- [x] Verify file integrity

### Phase C: Cohort Definition âœ…
- [x] Define MI labels (Acute, Pre-Incident)
- [x] Apply troponin criteria
- [x] Create control groups
- [x] Generate adjudication sample (100 cases)

### Phase D: Feature Engineering & VAE ðŸ”„
- [x] **D.1-D.2**: Extract clinical features (QRS, QT, HR)
- [x] **D.3**: Train Conv1D Î²-VAE (Currently: Epoch 15/160)
- [ ] **D.4**: Extract latent embeddings (Î¼ vectors)
- [ ] **D.5**: Validate interpretability (â‰¥10 dims, â‰¥95% plausible)

### Phase E: CATE Analysis (Pending)
- [ ] Baseline propensity score models
- [ ] Causal forest / S-learner
- [ ] Estimate heterogeneous treatment effects
- [ ] Identify high-risk subgroups

### Phase F: Validation (Pending)
- [ ] Clinical adjudication (inter-rater reliability)
- [ ] Negative control outcomes
- [ ] Sensitivity analyses

---

## ðŸ§  VAE Architecture

### Conv1D Î²-VAE Specifications
- **Input**: (batch, 12 leads, 5000 timesteps) at 500 Hz
- **Latent Dimension**: z_dim = 64
- **Î² Parameter**: Î² = 4.0 (cyclical annealing: 0 â†’ 4 â†’ 0, 4 cycles)
- **Free-Bits**: 2.0 (prevents posterior collapse)
- **Architecture**: 
  - Encoder: Conv1D (12â†’32â†’64â†’128) + FC (80kâ†’512â†’256â†’64)
  - Decoder: FC (64â†’256â†’512â†’80k) + ConvTranspose1D (128â†’64â†’32â†’12)
- **Parameters**: 82,424,076 total
- **Loss**: L = MSE(reconstruction) + Î² Ã— max(KL - free_bits, 0)

### Key Design Choices
1. **Cyclical Î²-Annealing**: 4 cycles Ã— 40 epochs prevents KL collapse
2. **Free-Bits Constraint**: Enforces minimum KL=2.0 per dimension
3. **Increased Capacity**: 82M params (up from 41M) for better reconstruction
4. **Batch Size 256**: Optimized for RTX 4050 (~70% GPU utilization)

---

## ðŸ“ˆ Training Commands

### Train VAE (Phase D.3)
```powershell
# Current training configuration
python src/models/train_vae.py `
    --batch_size 256 `
    --epochs 160 `
    --lr 1e-4 `
    --num_workers 0

# Monitor progress in real-time (terminal output shows epoch metrics)
```

### Extract Latent Embeddings (Phase D.4)
```powershell
# After training completes (best_model.pt)
python scripts/extract_latent_embeddings.py `
    --checkpoint models/checkpoints/vae_zdim64_beta4.0_*/best_model.pt `
    --batch_size 64
```

### Validate Interpretability (Phase D.5)
```powershell
# Dimension traversal analysis
python scripts/validate_latent_interpretability.py `
    --checkpoint models/checkpoints/vae_zdim64_beta4.0_*/best_model.pt `
    --save_plots
```

---

## ðŸŽ¯ Success Criteria

### Phase D.3 (VAE Training)
**Epoch 100 Targets:**
- KL_raw: 150-400 (healthy latent usage)
- Recon: 5,000-15,000 (good reconstruction)
- Learning Rate: 1e-5 to 5e-5 (properly reduced)

**Epoch 160 Targets (Final):**
- KL_raw: 200-350 (excellent), >150 (acceptable)
- Recon: 3,000-8,000 (excellent), 8,000-12,000 (good)
- Val/Train Gap: <2,000 (perfect), <5,000 (acceptable)

### Phase D.5 (Interpretability)
**Go/No-Go Criteria:**
- âœ… **PROCEED**: â‰¥10 interpretable dimensions AND â‰¥95% plausible ECGs
- âŒ **RETRAIN**: <10 interpretable OR <95% plausible

**Interpretable Dimension = One of:**
- Morphology: P/Q/R/S/T wave shape
- Intervals: PR, QRS, QT duration
- Rate: Heart rate changes
- Axis: Lead orientation shifts
- Noise: Baseline wander, artifacts

---

## ðŸ“ Output Files

### Training Outputs
```
models/checkpoints/vae_zdim64_beta4.0_20251102_073456/
â”œâ”€â”€ best_model.pt              # Best checkpoint (lowest val loss)
â”œâ”€â”€ checkpoint_epoch_10.pt     # Periodic checkpoint
â””â”€â”€ config.json                # Training hyperparameters
```

### Latent Embeddings
```
data/processed/ecg_z_embeddings.parquet
Columns: [subject_id, study_id, z_ecg_1, ..., z_ecg_64]
Shape: (47,852 ECGs Ã— 66 columns)
```

### Interpretability Results
```
results/latent_interpretability/
â”œâ”€â”€ dimension_plots/
â”‚   â”œâ”€â”€ dimension_001_traversal.png
â”‚   â”œâ”€â”€ dimension_002_traversal.png
â”‚   â””â”€â”€ ... (64 total)
â”œâ”€â”€ interpretability_results.csv
â””â”€â”€ latent_interpretability_report.md  # Go/No-Go decision
```

---

## ðŸ” Clinical Adjudication

### Adjudication Package
- **Sample**: 100 cases in `data/processed/adjudication_sample.csv`
- **Instructions**: `data/processed/ADJUDICATION_INSTRUCTIONS.md`
- **Quick Reference**: `data/processed/ADJUDICATION_QUICK_REFERENCE.md`
- **Email Template**: `data/processed/EMAIL_TEMPLATE.txt`

### Analysis Script
```powershell
# After receiving reviewed file
python scripts/analyze_adjudication.py
```

**Outputs:**
- Agreement rate & Cohen's Îº
- Confusion matrix
- Disagreement cases CSV

---

## âš™ï¸ Hardware Requirements

### Minimum Specifications
- GPU: NVIDIA RTX 3060 (6GB VRAM)
- RAM: 16GB
- Storage: 100GB free (for MIMIC-IV-ECG dataset)
- OS: Windows 10/11 with CUDA 12.1+

### Tested Configuration
- GPU: RTX 4050 Laptop (6.44 GB VRAM)
- RAM: 32GB
- CPU: 24 cores
- Training Speed: ~11s/batch (batch_size=256)

---

## ðŸ“š Key Dependencies

```
PyTorch:    2.5.1+cu121  # Deep learning framework
WFDB:       4.3.0        # ECG file I/O
NeuroKit2:  0.2.12       # ECG signal processing
PyArrow:    21.0.0       # Parquet file handling
NumPy:      2.2.6        # Numerical computing
Pandas:     2.3.3        # Data manipulation
Matplotlib: 3.10.7       # Visualization
```

Full list: See `requirements.txt`

---

## ðŸ› Troubleshooting

### Issue: OOM (Out of Memory) Error
```powershell
# Reduce batch size
python src/models/train_vae.py --batch_size 128 --epochs 160 --lr 1e-4 --num_workers 0
```

### Issue: KL Divergence â†’ 0 (Posterior Collapse)
**Current solution implemented:**
- Free-bits constraint (2.0)
- Cyclical Î²-annealing (4 cycles)
- Increased model capacity (82M params)

If still occurring, increase Î²:
```powershell
python src/models/train_vae.py --beta 8.0 --epochs 160 --num_workers 0
```

### Issue: Poor Reconstruction Quality
Reduce Î² for better reconstruction:
```powershell
python src/models/train_vae.py --beta 2.0 --epochs 160 --num_workers 0
```

### Issue: Slow Training
- Close background applications
- Check GPU temperature (thermal throttling)
- Reduce `--batch_size` if disk I/O is bottleneck

---

## ðŸ“– Documentation

- **DIRECTORY_AUDIT_REPORT.md**: Complete file structure analysis
- **data/processed/ADJUDICATION_*.md**: Clinical validation guides
- **reports/**: Phase-specific reports and figures

---

## ðŸ™ Acknowledgments

- **Dataset**: MIMIC-IV-ECG (Johnson et al., PhysioNet)
- **Validation**: PTB-XL & PTB-XL+ (Strodthoff et al., PhysioNet)
- **Tools**: PyTorch, WFDB, NeuroKit2

---

## ðŸ“ž Contact

For questions or issues:
1. Review `DIRECTORY_AUDIT_REPORT.md` for file organization
2. Check training logs in terminal output
3. Verify environment: `python scripts/preflight_vae_training.py`

---

**Last Updated:** November 2, 2025  
**Current Phase:** D.3 (VAE Training - Epoch 15/160)  
**Next Milestone:** Complete training â†’ Extract embeddings (D.4) â†’ Validate interpretability (D.5)
